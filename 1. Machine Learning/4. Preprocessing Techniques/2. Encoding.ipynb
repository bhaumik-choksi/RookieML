{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Often, features are in text or categorical form. For example, sizes \"Small\", \"Medium\", \"Large\", or ratings \"Good\", \"Average\", \"Bad\". However, machine learning models only operate on numerical values. \n",
    "\n",
    "## Solution\n",
    "Mapping each category or word to a number in such a way that the meaning of the word is retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical encoding example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical sizes are\n",
      "[1, 2, 3, 1, 2, 1, 2, 3, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# An array of sizes\n",
    "sizes = [\"S\", \"M\", \"L\", \"S\", \"M\", \"S\", \"M\", \"L\", \"M\", \"L\"]\n",
    "\n",
    "# A dictionary containing the mapping\n",
    "mapping = {\"S\": 1, \"M\": 2, \"L\": 3}\n",
    "\n",
    "numerical_sizes = list(map((lambda size : mapping[size]), sizes))\n",
    "print(\"Numerical sizes are\")\n",
    "print(numerical_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem with this approach\n",
    "Manually mapping each category to a number can be tedious, especially when the number of categories is large. Instead, we could assign a new index to each new category, and map the input automatically. \n",
    "Let's see how: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical colors are: \n",
      "[5, 6, 3, 3, 0, 2, 4, 1, 5, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "colors = [\"Red\", \"Yellow\", \"Green\", \"Green\", \"Purple\", \"Orange\", \"Blue\", \"White\", \"Red\", \"Black\", \"Yellow\"]\n",
    "\n",
    "unique_colors = list(set(colors)) # Set will contain only unique colors\n",
    "\n",
    "colors_numerical = list(map((lambda x : unique_colors.index(x)), colors))\n",
    "print(\"Numerical colors are: \")\n",
    "print(colors_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can skip this hassle of finding unique categories, thanks to Sklearn's LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 2 2 4 3 1 6 5 0 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "colors_numerical = le.fit_transform(colors)\n",
    "print(colors_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will this always work?\n",
    "\n",
    "Sometimes, directly mapping a word to a number can cause problems.\n",
    "Let's look the above example about colors. A color mapped to a smaller number will have less numerical weight as compared to a color mapped to a larger number. This is unfair, and can lead to poorly trained models.\n",
    "\n",
    "#### One-Hot Encoding\n",
    "What we could do instead is convert each value to an array, and have a particular index of the array set to HIGH, and the rest set to LOW (Hence the name \"One-Hot\"). This will make sure that only one value in the array is set to HIGH, and hence, eliminate the problem we discussed above. \n",
    "\n",
    "For instance, if we had Yes->1, No->2, Maybe->3, we could convert them to an array in the following manner : \n",
    "- Yes -> [1,0,0]\n",
    "- No -> [0,1,0]\n",
    "- Maybe -> [0,0,1]\n",
    "\n",
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoded values of colors are: \n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# We will be using the Keras library here\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "one_hot_colors = to_categorical(colors_numerical)\n",
    "\n",
    "print(\"One hot encoded values of colors are: \")\n",
    "for one_hot_color in one_hot_colors:\n",
    "    print(one_hot_color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
