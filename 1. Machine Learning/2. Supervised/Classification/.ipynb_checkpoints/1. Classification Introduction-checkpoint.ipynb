{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is classification?\n",
    "Classification is a supervised machine learning approach which aims to correctly classify a given input into one of many classes. For example, given the pixel data of an image, the classifier can classify the image as a cat, or a digit.\n",
    "![img](https://i.imgur.com/2hpxZwW.png)\n",
    "\n",
    "From a mathematical point of view, a classifier can be seen as one or more decision boundaries. A decision boundary is a line that seperates the inputs of 2 different classes on the graph. For a 2D plot, the decision boundary is a line. For a 3D plot, it is a plane, and so on...\n",
    "- - - -\n",
    "The goal of training a classifier is to find these decision boundaries :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is classification different from regression? \n",
    "Regression is primarily used for prediction tasks (like predicting house prices) whereas classification is used to find out what class an input belongs to. In other words, regression is used for a continous-valued output, and classification is used for a discrete-valued output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does everyone use the same algorithm to classify?\n",
    "NO! There's a ton of classification algorithms out there, and one can pick whatever suits their needs the best. Here are some popular ones, in no particular order - \n",
    "- Logistic Regression (Don't get confused by the terminology, logistic \"regression\" is actually a classifier :P)\n",
    "- Naive Baiyes (Not as \"naive\" as it sounds, gives pretty good results in most cases. Based on probability.)\n",
    "- Decision Tree (Consists of several if-else like conditions, which the classifier learns on its own from the given data)\n",
    "- Random Forests (A forest is a bunch of trees. A Random Forest is a bunch of Decision Trees.)\n",
    "- Support Vector Machines or SVMs (Can use the \"kernel trick\" to classify data that is not linearly seperable by mapping it to a higher dimension. ~~Interstellar~~)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very simple example\n",
    "\n",
    "Consider an example where we try to classify a movie as good or bad based on its ratings (R) and its first day collection (C).\n",
    "The output classes are \"Good\" = 1 and \"Bad\" = 0.\n",
    "Here's the training data:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>R</th>\n",
    "        <th>C</th>\n",
    "        <th>Result</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>4</td>\n",
    "        <td>1000</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>250</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>700</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5</td>\n",
    "        <td>600</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>450</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a decision tree classifier using scikit-learn and see what the results look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the input data X and the output data Y. \n",
    "# Note that the input data has 2 dimensions, since we have 2 input features.\n",
    "\n",
    "X = [[4,1000],[2,250],[3,700],[5,600],[2,450]]\n",
    "Y = [1,0,1,1,0]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Let's try classifying a new movie with R=1 and C=50!\n",
    "X_new = [[1,50]]\n",
    "prediction = dtree.predict(X_new)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Now let's try a movie that with R=5 and C=2000 (you know it's good :P)\n",
    "X_new = [[5,2000]]\n",
    "prediction = dtree.predict(X_new)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We did it! \n",
    "Our classifier learned that low ratings combined with low collections mean that a movie is bad. We never explicitly told the classifier about any of these patterns, it figured this out on its own. The results demonstrate how our classifier \"learned\" what a good movie looks like. The mathematics behind this is quite interesting and is explained really well [here](http://www.doc.ic.ac.uk/~sgc/teaching/pre2012/v231/lecture11.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
