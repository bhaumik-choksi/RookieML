{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the MNIST dataset? \n",
    "The MNIST dataset is a large set of images of handwritten digits. It is probably the most common dataset used to test deep learning models that operate on images or perform image processing. It contains 28x28 images, each containing a handwritten digit from 0-9. Every image has an output label associated with it, denoting the digit represented by the image.\n",
    "\n",
    "![](http://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png)\n",
    "\n",
    "The input dimensions of the input are (N, 28, 28) and the output dimensions are (N) where N is the number of samples under consideration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAFhhJREFUeJzt3XmYHHWdx/H3h5yQBEgMxARCEjFya9SR4wGBFeVafcBVjiyPCwgGFEQUFch6oAuILsKCIG4QFlBuAYnCipgHQR5IJLAxHOFMAuQmhJBwhWTy3T+qBjrDdE1Pd890J7/P63nmmZ7+1vHtmv5UVVd1dykiMLP0bNToBsysMRx+s0Q5/GaJcvjNEuXwmyXK4TdLVNOFX9JZkn7b6D56mqTRkkJS7wqG3VfSvCrnUziupD0lPSPpNUmHVjOPCnqYK+nTZWqflPRUFdP8laTv195d95G0Tb5cezW6F2hA+PMH3/azVtKbJX8f1dP9lCPpr5KOb9bpdaMfA5dExMCI+H2tE5N0laSzKx0+Iv4WEdt1dT4RcWJE/EdXx+tJEfFCvlxba5mOpGMktbbL0r5dnU6Phz9/8AMjYiDwAvC5kvuu7el+7D1GAY9XM2Iley1WNw+WZiki/trVCTTdbn+ur6RrJK2U9LiklraCpBGSbpH0kqQ5kk4pNxFJm+XTeUnS85K+J2mjvLbOy4vS3W5J5wCfBC7J16qX5MOEpFMkzZa0VNJ/1jK9IpKOlTQrXwazJZ3QwTAT8z7mlu41Seon6XxJL0hanO8Sb1zBPJ8DPgD8Ie+zX768J0taJulZSV8pGf4sSb+T9FtJK4Bj2k1vAnAU8N18en8oKY+TNFPSq5JulNQ/H2edlyWSTpc0P18OT0nar0zv7+xhtE1D0nclLZG0UNKhkg6W9HT+WCaWjLurpAclLc+HvURS35L6/vm8X5X0S0n3lu7FSfpy/r96RdJdkkaV6XGdl3b5Fnx2/tjmqKf3fCOiYT/AXODT7e47C3gLOBjoBfwEmJrXNgIeBn4A9CV7os4GDigz/WuA24FBwGjgaeC4kvn8tmTY0UAAvfO//woc3256AdwDDAG2yad3fLXTazft9sP/M7AtIGAf4A3gY3ltX2ANcAHQL6+/DmyX1y8EJud9DgL+APykZNx5lf5PgPuAXwL9gXHAS8CnSh7zauDQ/H+zcQfTuwo4u4N5/B0Ykfc4CzixfX/AdsCLwIiSZbRtmb7fmU/J8vkB0Af4St73dfny2Al4ExiTD/9xYHegdz6PWcCpeW0osAL4l7z+jfwxt/3fDwGeBXbI698DHujsfwwMyKfb9j8bDuyU394GWA5sU2Y6x+T/76Vkz8Hvkz9vuvLTrFv++yPizvy10W+Aj+T3fwLYIiJ+HBFvR8Rs4HLgyPYTUHZQ5UjgzIhYGRFzgZ8DX6qxt59GxLKIeAH4L2B8jdPrUETcERHPReZe4M9kew+lvh8Rq/L6HcDhkgRMAL6Z97kSOJcOllFnJI0E9gROj4i3ImIG8Gvg30oGezAifh8RayPizS5M/uKIWBARy8hWTuM6GKaVbOW2o6Q+ETE3Ip6rcPqrgXMiYjVwA1mIL8qfC48DT5A/ryLi4YiYGhFr8ufJf5OtUCHbCD0eEbdGxBrgYmBRyXxOJFuxzsrr55Lt1XS49W9nLbCzpI0jYmHeV9uxgc3z51hH7gN2BrYEvkD2HPxORUulRLOGv3ThvgH0z3eVRgEj8t2z5ZKWAxOBYR1MYyjZWv/5kvueB7aqsbcX201vRI3T65CkgyRNzXdRl5M9CYeWDPJKRLzeQS9bAJsAD5csoz/l93fVCKBtBVI6n9Jl+CLVaf8/Hth+gIh4FjiVbA9jiaQbJFW6vF+Odw+sta2UFpfU32ybp6QPSfqjpEX5y5dzeXdZj6DkMUa26S09WzIKuKhkWS8j21srfJ7l/7sjyFYeCyXdIWn7Sh5YRMyOiDn5CvdRsoO0X6xk3FLNGv5yXgTm5GvFtp9BEXFwB8MuJVv7l66BtwHm57dfJwtJm/e3G7/cxx1Htpveghqn9x6S+gG3AOcDwyJic+BOsidVm8GSBnTQy1KyJ/ZOJctos8gOsHbVAmCIpEHt5jO/5O/OHldNHxuNiOsiYi+y/2MAP61lemVcBjwJjI2ITck2KG3LeiGwdduA+Z7V1iXjvgic0O45uXFEPNDZTCPiroj4DNku/5Nke7HVCNZ9blRkfQv/34GV+UGgjSX1krSzpE+0HzBf698EnCNpUL4b9i2g7aDcDGBvZedeNwPObDeJxWTHFNr7jqTB+S7xN4Aba5xeR/qS7e6+BKyRdBCwfwfD/UhSX0mfBD4L3BwRa8meRBdK2hJA0laSDqhw3u+IiBeBB4CfSOov6cPAcby7DCvRlce9DknbSfpUvjJ8i2yltraaaXViENnr79fyre9XS2p3ALvkBwx7Ayex7or9V8CZknbKe95M0mGdzVDSMEmH5CvwVcBrVPjY8r3CYfnt7cle899eybil1qvw54H+LNnrwzlkW7lfA5uVGeXrZFvk2cD9ZAd8rsyndTdZcGeSHUT8Y7txLwK+mB/Bvbjk/tvz4WeQPTGuqHF6HT3OlcApZCuvV4B/JTuAV2pRXlsAXEt2wOzJvHY62UGoqflu7F/IDp5VYzzZgaoFwG3ADyPiL10Y/wqy1+zLJXX1fQP9gPPI/s+LyF7jtl+p1sO3yZbxSrIVZ9sKnYhYChwG/Ax4GdgRmE4WWCLiNrK9kRvyZf0YcFAF89yIbGO0gOylwj7kKx29+2agbcqMux8wU9LrZHuEt5K9VOkShb/Mo2KSgmzX8NlG92KNoezU7jzgqIi4p9H91GK92vKbNYKkAyRtnr/8aDseMLXBbdXM4Tfr3B7Ac2QvPz4HHNrF05pNybv9Zonylt8sUT36QYy+6hf9GdD5gGZWlbd4nbdjVUXn/GsKv6QDyU5h9QJ+HRHnFQ3fnwHs1vHnMsysDqbFlIqHrXq3P3/v/KVk5zR3BMZL2rHa6ZlZz6rlNf+uwLP5+4zfJvvwxCH1acvMulst4d+KdT/UMY8OPswgaYKk6ZKmr87eFGVmTaDbj/ZHxKSIaImIlj706+7ZmVmFagn/fNb9hNvWrPtpLzNrYrWE/yFgrKQx+VceHcl7P3xiZk2q6lN9EbFG0snAXWSn+q5s+yYSM2t+NZ3nj4g7yT5SaGbrGb+91yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNElXTVXqt+al38b+41xZDu3X+T317dNla6yZrC8cdte2SwvomX1NhfdEFfcvWHmm5sXDcpa2vF9Z3u/m0wvoHvzW1sN4Magq/pLnASqAVWBMRLfVoysy6Xz22/P8UEUvrMB0z60F+zW+WqFrDH8CfJT0saUJHA0iaIGm6pOmrWVXj7MysXmrd7d8rIuZL2hK4W9KTEXFf6QARMQmYBLCphkSN8zOzOqlpyx8R8/PfS4DbgF3r0ZSZdb+qwy9pgKRBbbeB/YHH6tWYmXWvWnb7hwG3SWqbznUR8ae6dLWB6bXD2MJ69OtTWF+wz+aF9Td3L39Oeshmxeer//aR4vPdjfS/bwwqrP/0kgML69N2ua5sbc7qNwvHPW/xZwrrI/62/r+CrTr8ETEb+EgdezGzHuRTfWaJcvjNEuXwmyXK4TdLlMNvlih/pLcOWvf9WGH9gqsuLax/qE/5j55uyFZHa2H9B784prDe+/Xi02173Hxy2dqg+WsKx+23tPhU4CbTpxXW1wfe8pslyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmifJ5/jro99SCwvrDb40srH+oz+J6tlNXpy3cvbA++7Xir/6+atvfla29urb4PP2wix8orHen9f8Du53zlt8sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5Qieu6M5qYaErtpvx6bX7NYduwehfUVBxZ/vXavmQML6//42i+63FObs5d+uLD+0D7F5/Fbl79aWI89yn/B89xTCkdlzPh/FA9g7zEtprAilhVfuzznLb9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliif528CvYa+r7De+vKywvqc68qfq3987ysLx9313K8X1re8tHGfqbeuq+t5fklXSloi6bGS+4ZIulvSM/nvwbU0bGY9r5Ld/quAA9vddwYwJSLGAlPyv81sPdJp+CPiPqD9fuchwNX57auBQ+vcl5l1s2q/w29YRCzMby8ChpUbUNIEYAJAfzapcnZmVm81H+2P7Ihh2aOGETEpIloioqUP/WqdnZnVSbXhXyxpOED+e0n9WjKznlBt+CcDR+e3jwZur087ZtZTOn3NL+l6YF9gqKR5wA+B84CbJB0HPA8c3p1Nbuhal75c0/irV/StetydjnqisP7SZb2KJ7C2tep5W2N1Gv6IGF+m5HfrmK3H/PZes0Q5/GaJcvjNEuXwmyXK4TdLlC/RvQHY4fSny9aO3aX4pMz/jJpSWN/nsJMK64NunFpYt+blLb9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliif598AFF0m++Wv7lA47guT3yysn3H2NYX1Mw//fGE9/m+zsrWR5zxYOC49+LXyKfKW3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlC/RnbhlX96jsH7tD88vrI/p3b/qee90zcmF9bGXLyysr5k9t+p5b6jqeoluM9swOfxmiXL4zRLl8JslyuE3S5TDb5Yoh98sUT7Pb4Viz3GF9U3Pm1dYv/4Dd1U97+3vOb6wvt2Pyn+PAUDrM7Ornvf6qq7n+SVdKWmJpMdK7jtL0nxJM/Kfg2tp2Mx6XiW7/VcBB3Zw/4URMS7/ubO+bZlZd+s0/BFxH7CsB3oxsx5UywG/kyXNzF8WDC43kKQJkqZLmr6aVTXMzszqqdrwXwZsC4wDFgI/LzdgREyKiJaIaOlDvypnZ2b1VlX4I2JxRLRGxFrgcmDX+rZlZt2tqvBLGl7y5+eBx8oNa2bNqdPz/JKuB/YFhgKLgR/mf48DApgLnBARxR++xuf5N0S9hm1ZWF9wxAfL1qadflHhuBt1sm06as7+hfVX93q5sL4h6sp5/k4v2hER4zu4+4oud2VmTcVv7zVLlMNvliiH3yxRDr9Zohx+s0T5I73WMDfNK75E9ybqW1h/I94urH/266eWn/Zt0wrHXV/5q7vNrFMOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0tUp5/qs7St3av4q7ufO6z4Et07j5tbttbZefzO/GLZRwvrm9w+vabpb+i85TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXz/Bs4texcWH/6lOJz7ZfveXVhfe/+xZ+pr8WqWF1Yn7psTPEE1nb6bfJJ85bfLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0tUp+f5JY0ErgGGkV2Se1JEXCRpCHAjMJrsMt2HR8Qr3ddqunqPGVVYf+7YEWVrZx1xQ+G4Xxi4tKqe6mHi4pbC+r0X7V5YH3x18ff+W7FKtvxrgNMiYkdgd+AkSTsCZwBTImIsMCX/28zWE52GPyIWRsQj+e2VwCxgK+AQoO3tX1cDh3ZXk2ZWf116zS9pNPBRYBowLCLa3j+5iOxlgZmtJyoOv6SBwC3AqRGxorQW2QX/Orzon6QJkqZLmr6aVTU1a2b1U1H4JfUhC/61EXFrfvdiScPz+nBgSUfjRsSkiGiJiJY+9KtHz2ZWB52GX5KAK4BZEXFBSWkycHR++2jg9vq3Z2bdpZKP9O4JfAl4VNKM/L6JwHnATZKOA54HDu+eFtd/vUdvU1h/9ePDC+tH/PhPhfUTN7+1sN6dTltYfDruwV+WP5035Kq/F447eK1P5XWnTsMfEfcD5a73vV992zGznuJ3+JklyuE3S5TDb5Yoh98sUQ6/WaIcfrNE+au7K9R7+PvL1pZdOaBw3K+OubewPn7Q4qp6qoeT5+9VWH/ksuJLdA/93WOF9SErfa6+WXnLb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8JslKpnz/G8fUPw10W9/c1lhfeIH7yxb23/j16vqqV4Wt75Ztrb35NMKx93+e08W1ocsLz5Pv7awas3MW36zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFHJnOefe2jxeu7pXW7utnlfunzbwvpF9+5fWFdruW9Oz2x/9pyytbGLpxWO21pYtQ2Zt/xmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIUEcUDSCOBa4BhQACTIuIiSWcBXwFeygedGBHlP/QObKohsZt8VW+z7jItprAilhW/MSRXyZt81gCnRcQjkgYBD0u6O69dGBHnV9uomTVOp+GPiIXAwvz2SkmzgK26uzEz615des0vaTTwUaDtPaMnS5op6UpJg8uMM0HSdEnTV7OqpmbNrH4qDr+kgcAtwKkRsQK4DNgWGEe2Z/DzjsaLiEkR0RIRLX3oV4eWzaweKgq/pD5kwb82Im4FiIjFEdEaEWuBy4Fdu69NM6u3TsMvScAVwKyIuKDk/uElg30eKL5cq5k1lUqO9u8JfAl4VNKM/L6JwHhJ48hO/80FTuiWDs2sW1RytP9+oKPzhoXn9M2sufkdfmaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRnX51d11nJr0EPF9y11BgaY810DXN2luz9gXurVr17G1URGxRyYA9Gv73zFyaHhEtDWugQLP21qx9gXurVqN6826/WaIcfrNENTr8kxo8/yLN2luz9gXurVoN6a2hr/nNrHEaveU3swZx+M0S1ZDwSzpQ0lOSnpV0RiN6KEfSXEmPSpohaXqDe7lS0hJJj5XcN0TS3ZKeyX93eI3EBvV2lqT5+bKbIengBvU2UtI9kp6Q9Likb+T3N3TZFfTVkOXW46/5JfUCngY+A8wDHgLGR8QTPdpIGZLmAi0R0fA3hEjaG3gNuCYids7v+xmwLCLOy1ecgyPi9Cbp7SzgtUZftj2/mtTw0svKA4cCx9DAZVfQ1+E0YLk1Ysu/K/BsRMyOiLeBG4BDGtBH04uI+4Bl7e4+BLg6v3012ZOnx5XprSlExMKIeCS/vRJou6x8Q5ddQV8N0YjwbwW8WPL3PBq4ADoQwJ8lPSxpQqOb6cCwiFiY314EDGtkMx3o9LLtPandZeWbZtlVc7n7evMBv/faKyI+BhwEnJTv3jalyF6zNdO52oou295TOris/Dsaueyqvdx9vTUi/POBkSV/b53f1xQiYn7+ewlwG8136fHFbVdIzn8vaXA/72imy7Z3dFl5mmDZNdPl7hsR/oeAsZLGSOoLHAlMbkAf7yFpQH4gBkkDgP1pvkuPTwaOzm8fDdzewF7W0SyXbS93WXkavOya7nL3EdHjP8DBZEf8nwP+vRE9lOnrA8A/8p/HG90bcD3ZbuBqsmMjxwHvA6YAzwB/AYY0UW+/AR4FZpIFbXiDetuLbJd+JjAj/zm40cuuoK+GLDe/vdcsUT7gZ5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8Jsl6v8B+MDKcq+bxqUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x217356a2208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is  (60000, 28, 28)\n",
      "The shape of y_train is  (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Let us import some libraries first\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Keras comes with the MNIST dataset built-in!\n",
    "from keras.datasets import mnist \n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Let's plot one of the samples\n",
    "plt.imshow(x_train[0])\n",
    "plt.title(\"The output label for this image is: \"+ str(y_train[0]))\n",
    "plt.show()\n",
    "\n",
    "# Let us also see the shape of the data\n",
    "print(\"The shape of x_train is \", x_train.shape)\n",
    "print(\"The shape of y_train is \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, let us quickly build a simple classifier using keras\n",
    "First, we'll need to do some preprocessing - Since we're using a simple feedforward network, the input must be one-dimensional. \n",
    "However, our input data consists of images, so we'll have to find a way to convert 2D images to 1D input that can be fed into the network. The simplest way to do this is to flatten our images into a vector. Hence, we'll be converting our 28x28 image to a vector of length 784 (28*28 = 784). We'll also convert our output labels to one-hot encoded vectors since we're performing multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 20s 326us/step - loss: 0.4075 - acc: 0.88502s - loss: 0.4113 - acc - ETA: 1s - los\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.3353 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 0.3186 - acc: 0.9102\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s 324us/step - loss: 0.3112 - acc: 0.9132\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 21s 343us/step - loss: 0.3028 - acc: 0.9152\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.2957 - acc: 0.9163\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.2909 - acc: 0.9182\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.2867 - acc: 0.9199\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.2843 - acc: 0.9192\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.2809 - acc: 0.9209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217356d59b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some basic normalization for the pixel intensities\n",
    "# Note that MNIST has grayscale images\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# Flattening the input\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1,784)\n",
    "\n",
    "# One-hot encoding for the output\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(784, input_shape=(784, )))\n",
    "model.add(Dense(784))\n",
    "model.add(Dense(10, activation=\"softmax\")) # Because we have 10 output classes\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 266us/step\n",
      "Final score: Loss= 0.2993020266771316  Accuracy = 91.9 %\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(\"Final score: Loss=\",loss,\" Accuracy =\",acc * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 1,238,730\n",
      "Trainable params: 1,238,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neat!\n",
    "We trained a feed-forward network to classify MNIST images. The accuracy was pretty good too!\n",
    "Remember that good preprocessing is as important as building a powerful model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
